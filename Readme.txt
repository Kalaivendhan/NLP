Steps:

1. Tokenization - break into sentences / words
2. Stopword (Words that provide structure / Gramatical purpose) Removal - and/the
3. N-Grams - Common occuring words, Group of words that occur together e.g: Newyork - Bigram
